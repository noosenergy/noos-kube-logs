# All container logs are maintained as symlinks onto the node

pipeline:
  inputs:
    - name: tail
      tag: kubernetes.*
      read_from_head: true
      # Don't collect logs for all system pods
      exclude_path: /var/log/containers/*_kube-*
      path: /var/log/containers/*.log
      # Log parsing
      multiline.parser: docker, cri
      skip_long_lines: on
      # Storage activated
      storage.type: filesystem
      db: /var/fluent-bit/state/containers.db
      mem_buf_limit: 50MB
      refresh_interval: 10

  filters:
    # Add kubernetes metadata
    - name: kubernetes
      match: "kubernetes.*"
      # To precise given a custom tag
      kube_tag_prefix: kubernetes.var.log.containers.
      merge_log: on
      keep_log: off
      labels: off

    # Remove some fields from the log record
    - name: record_modifier
      match: "kubernetes.*"
      remove_key:
        - _p
        - time

    # Dynamically restructure log format
    # move all keys except timestamp and kubernetes under 'log_object'
    - name: lua
      match: "kubernetes.*"
      script: /fluent-bit/etc/restructure_log.lua
      call: restructure_log

    # Don't emit logs for all Jupyter-related pods
    - name: grep
      match: "kubernetes.*"
      exclude:
        - $kubernetes['namespace_name'] .*-hub

    # Don't emit logs for fluent-bit pods
    - name: grep
      match: "kubernetes.*"
      exclude:
        - $kubernetes['pod_name'] .*fluent-bit.*

    # Don't emit whitelisted logs
    - name: grep
      match: "kubernetes.*"
      exclude:
        - $log_object['whitelisted'] true

  outputs:
    # Push kubernetes and services logs to Datadog
    - name: datadog
      match_regex: "(kubernetes..*)|(services..*)"
      host: ${FLUENTBIT__DATADOG_HOST}
      tls: on
      compress: gzip
      apikey: ${FLUENTBIT__DATADOG_API_KEY}
      dd_service: kube-logs
      dd_source: fluent-bit
      dd_tags: env:noos-prod
      dd_message_key: log
